{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a66dfa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c7f189",
   "metadata": {},
   "source": [
    "# 1.2 Filtered Boston housing and kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74a8919",
   "metadata": {},
   "source": [
    "## 1.2.4: Baseline vs full linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32015d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data():\n",
    "    df = pd.read_csv(\"boston_data.csv\")\n",
    "    df_train = df.sample(frac=2.0/3)\n",
    "    df_test = df.drop(df_train.index)\n",
    "\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "    X_train = df_train.drop(\"MEDV\", axis=1).to_numpy()\n",
    "    y_train = df_train[\"MEDV\"].to_numpy()\n",
    "\n",
    "    X_test = df_test.drop(\"MEDV\", axis=1).to_numpy()\n",
    "    y_test = df_test[\"MEDV\"].to_numpy()\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8fcad3",
   "metadata": {},
   "source": [
    "### Part (a) - Linear regression with constant function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6ffb0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train: 83.09053139501097\n",
      "STDEV train: 5.341849964301301\n",
      "MSE test:  87.26859662282831\n",
      "STDEV test: 10.58976103768394\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def constant_regression():\n",
    "    \"\"\"Fits a constant to the data set using linear regression\"\"\"\n",
    "\n",
    "    mse_train_values = []\n",
    "    mse_test_values = []\n",
    "\n",
    "    for _ in range(20):\n",
    "\n",
    "        X_train, y_train, X_test, y_test = get_train_test_data()\n",
    "\n",
    "        m_train, m_test = len(X_train), len(X_test)\n",
    "\n",
    "        phi_train = np.ones(m_train).reshape(-1, 1)\n",
    "\n",
    "        a = np.linalg.lstsq(phi_train, y_train)[0] # best fit constant\n",
    "        mse_train = (1.0/m_train) * np.linalg.norm(np.dot(phi_train, a) - y_train)**2\n",
    "        mse_train_values.append(mse_train)\n",
    "\n",
    "        phi_test = np.ones(m_test).reshape(-1, 1)\n",
    "\n",
    "        mse_test = (1.0/m_test) * np.linalg.norm(np.dot(phi_test, a) -  y_test)**2\n",
    "        mse_test_values.append(mse_test)\n",
    "    \n",
    "    print(f\"MSE train: {np.mean(mse_train_values)}\")\n",
    "    print(f\"STDEV train: {np.std(mse_train_values)}\")\n",
    "    print(f\"MSE test:  {np.mean(mse_test_values)}\")\n",
    "    print(f\"STDEV test: {np.std(mse_test_values)}\")\n",
    "\n",
    "\n",
    "constant_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c64008",
   "metadata": {},
   "source": [
    "### Part (c) - Linear regression with a single attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "074eba55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressing on variable 0\n",
      "MSE train: 71.31073711451387\n",
      "STDEV train: 4.321244317475169\n",
      "MSE test:  73.00318014754522\n",
      "STDEV test: 8.664325342583926\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 1\n",
      "MSE train: 71.93026048797451\n",
      "STDEV train: 4.664719549309076\n",
      "MSE test:  76.94384464743798\n",
      "STDEV test: 9.316406784960927\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 2\n",
      "MSE train: 63.52588614682338\n",
      "STDEV train: 4.113638203333017\n",
      "MSE test:  67.24649167119055\n",
      "STDEV test: 8.264101737314547\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 3\n",
      "MSE train: 81.44579383372039\n",
      "STDEV train: 4.95134722045434\n",
      "MSE test:  83.12461280051681\n",
      "STDEV test: 9.874930707759344\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 4\n",
      "MSE train: 68.94506634458135\n",
      "STDEV train: 3.9823797818889917\n",
      "MSE test:  69.41177884236326\n",
      "STDEV test: 8.113710379438976\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 5\n",
      "MSE train: 44.01665217695546\n",
      "STDEV train: 3.6455235856509858\n",
      "MSE test:  43.222268808617756\n",
      "STDEV test: 7.225440416189414\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 6\n",
      "MSE train: 73.04974255558369\n",
      "STDEV train: 5.131783651905555\n",
      "MSE test:  71.63401149938292\n",
      "STDEV test: 10.34188888949954\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 7\n",
      "MSE train: 78.02934764564347\n",
      "STDEV train: 4.786426917797488\n",
      "MSE test:  81.68660955108112\n",
      "STDEV test: 9.621628562597804\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 8\n",
      "MSE train: 73.75635440698264\n",
      "STDEV train: 4.2676213672865\n",
      "MSE test:  69.28349860562312\n",
      "STDEV test: 8.449923815413245\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 9\n",
      "MSE train: 65.16833641121566\n",
      "STDEV train: 5.400150112965919\n",
      "MSE test:  67.61015340061869\n",
      "STDEV test: 10.675940544179852\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 10\n",
      "MSE train: 60.69208996701078\n",
      "STDEV train: 3.8597094590624077\n",
      "MSE test:  66.99580087362838\n",
      "STDEV test: 7.815768997124751\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 11\n",
      "MSE train: 37.416403382994424\n",
      "STDEV train: 3.105861815607876\n",
      "MSE test:  41.14740970787537\n",
      "STDEV test: 6.485711271277864\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def single_attribute_regression(index):\n",
    "    \"\"\"Does linear regression with a bias term with a single attribute given by the index. \"\"\"\n",
    "    \n",
    "    mse_train_values = []\n",
    "    mse_test_values = []\n",
    "\n",
    "    for _ in range(20):\n",
    "\n",
    "        X_train, y_train, X_test, y_test = get_train_test_data()\n",
    "        m_train, m_test = len(X_train), len(X_test)\n",
    "\n",
    "        X_train = X_train[:, index]\n",
    "        phi_train = np.column_stack((X_train, np.ones_like(X_train)))\n",
    "        \n",
    "\n",
    "        X_test = X_test[:, index]\n",
    "        phi_test = np.column_stack((X_test, np.ones_like(X_test)))\n",
    "\n",
    "        w = np.linalg.lstsq(phi_train, y_train)[0] # best fit weight vector\n",
    "        mse_train = (1.0/m_train) * np.linalg.norm(np.dot(phi_train, w) - y_train)**2\n",
    "        mse_train_values.append(mse_train)\n",
    "\n",
    "        mse_test = (1.0/m_test) * np.linalg.norm(np.dot(phi_test, w) -  y_test)**2\n",
    "        mse_test_values.append(mse_test)\n",
    "    \n",
    "    print(f\"MSE train: {np.mean(mse_train_values)}\")\n",
    "    print(f\"STDEV train: {np.std(mse_train_values)}\")\n",
    "    print(f\"MSE test:  {np.mean(mse_test_values)}\")\n",
    "    print(f\"STDEV test: {np.std(mse_test_values)}\")\n",
    "\n",
    "\n",
    "for i in range(12):\n",
    "    print(f\"Regressing on variable {i}\")\n",
    "    single_attribute_regression(i)\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b5504f",
   "metadata": {},
   "source": [
    "### Part (d) - Linear regression with all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b01f0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train: 21.68136305461265\n",
      "STDEV train: 2.2325003246302426\n",
      "MSE test:  25.62333988655688\n",
      "STDEV test: 4.864137282101709\n"
     ]
    }
   ],
   "source": [
    "def all_attributes_regression():\n",
    "    \"\"\"Does linear regression with a bias term with a single attribute given by the index. \"\"\"\n",
    "    \n",
    "    mse_train_values = []\n",
    "    mse_test_values = []\n",
    "\n",
    "    for _ in range(20):\n",
    "\n",
    "        X_train, y_train, X_test, y_test = get_train_test_data()\n",
    "        m_train, m_test = len(X_train), len(X_test)\n",
    "        phi_train = np.column_stack((X_train, np.ones(m_train)))\n",
    "\n",
    "        w = np.linalg.lstsq(phi_train, y_train)[0] \n",
    "        mse_train = (1.0/m_train) * np.linalg.norm(np.dot(phi_train, w) - y_train)**2\n",
    "        mse_train_values.append(mse_train)\n",
    "\n",
    "        phi_test = np.column_stack((X_test, np.ones(m_test)))\n",
    "        mse_test = (1.0/m_test) * np.linalg.norm(np.dot(phi_test, w) -  y_test)**2\n",
    "        mse_test_values.append(mse_test)\n",
    "    \n",
    "    print(f\"MSE train: {np.mean(mse_train_values)}\")\n",
    "    print(f\"STDEV train: {np.std(mse_train_values)}\")\n",
    "    print(f\"MSE test:  {np.mean(mse_test_values)}\")\n",
    "    print(f\"STDEV test: {np.std(mse_test_values)}\")\n",
    "\n",
    "all_attributes_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9432e11",
   "metadata": {},
   "source": [
    "# 1.3 Filtered Boston housing and kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a681e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KRR:\n",
    "\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.pairwise_norm = self._get_pairwise_norm(X_train)\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def _get_pairwise_norm(self, X_train):\n",
    "        m = len(X_train)\n",
    "        M = np.zeros((m, m))\n",
    "        for i in range(m):\n",
    "            for j in range(m):\n",
    "                M[i, j] = np.linalg.norm(X_train[i] - X_train[j])\n",
    "        return M\n",
    "\n",
    "    def get_alpha(self, gamma, sigma):\n",
    "        m = len(self.y_train)\n",
    "        K = np.exp(-((self.pairwise_norm/sigma)**2)/2.0)\n",
    "        M = K + gamma * m * np.identity(m)\n",
    "        alpha = np.linalg.solve(M, self.y_train)\n",
    "        return alpha\n",
    "        \n",
    "    def predict(self, X_test, gamma, sigma):\n",
    "        alpha = self.get_alpha(gamma, sigma)\n",
    "        diff = self.X_train[:, None, :] - X_test[None, :, :] # diff[i][j] = X_train[i] - X_test[j]\n",
    "        norms = np.linalg.norm(diff, axis=2) # norms[i][j] = ||X_train[i] - X_test[j]||\n",
    "\n",
    "        k = np.exp(-((norms/sigma)**2)/2)\n",
    "\n",
    "        y_preds = np.dot(alpha, k) # dots alpha with each column of norms\n",
    "\n",
    "        return y_preds\n",
    "\n",
    "    def get_mse(self, X_test, y_test, gamma, sigma):\n",
    "        y_preds = self.predict(X_test, gamma, sigma)\n",
    "    \n",
    "        return (np.linalg.norm(y_preds - y_test)**2)/len(X_test)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43152bc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjoblib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Parallel, delayed\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_cross_validation_error\u001b[39m(folds_X, folds_y, gamma, sigma):\n\u001b[32m      5\u001b[39m     num_folds = \u001b[38;5;28mlen\u001b[39m(folds_X)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'joblib'"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def get_cross_validation_error(folds_X, folds_y, gamma, sigma):\n",
    "\n",
    "    num_folds = len(folds_X)\n",
    "\n",
    "    def get_fold_error(i):\n",
    "        fold_X_test = folds_X[i]\n",
    "        fold_y_test = folds_y[i]\n",
    "        fold_X_train = np.concatenate([folds_X[j] for j in range(num_folds) if j != i])\n",
    "        fold_y_train = np.concatenate([folds_y[j] for j in range(num_folds) if j != i])\n",
    "        krr = KRR(fold_X_train, fold_y_train)\n",
    "        return krr.get_mse(fold_X_test, fold_y_test, gamma, sigma)\n",
    "    \n",
    "    errors = Parallel(n_jobs=-1)(delayed(get_fold_error)(i) for i in range(num_folds))\n",
    "\n",
    "    return np.mean(errors)\n",
    "\n",
    "\n",
    "def get_best_params(X_train, y_train):\n",
    "    \"\"\"Gets the best pair of values (gamma, sigma) to use for ridge regression.\n",
    "    by doing five-fold validation on the given training data.\"\"\"\n",
    "\n",
    "    num_folds = 5\n",
    "    gammas = 2.0 ** np.arange(-40, -25)\n",
    "    sigmas = 2.0 ** np.arange(7.0, 13.1, 0.5)\n",
    "\n",
    "    folds_X = np.array_split(X_train, num_folds)\n",
    "    folds_y = np.array_split(y_train, num_folds)\n",
    "\n",
    "    min_cross_error = np.inf\n",
    "\n",
    "    best_gamma, best_sigma = 0, 0\n",
    "\n",
    "    for gamma in gammas:\n",
    "        for sigma in sigmas:\n",
    "            \n",
    "            cross_error = get_cross_validation_error(folds_X, folds_y, gamma, sigma)\n",
    "            if cross_error < min_cross_error:\n",
    "                min_cross_error = cross_error\n",
    "                best_gamma, best_sigma = gamma, sigma\n",
    "\n",
    "            print(cross_error)\n",
    "\n",
    "    return best_gamma, best_sigma\n",
    "    \n",
    "\n",
    "X_train, y_train, X_test, y_test = get_train_test_data()\n",
    "get_best_params(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
