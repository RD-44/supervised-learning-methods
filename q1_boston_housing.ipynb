{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a66dfa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c7f189",
   "metadata": {},
   "source": [
    "# 1.2 Filtered Boston housing and kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74a8919",
   "metadata": {},
   "source": [
    "## 1.2.4: Baseline vs full linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32015d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data():\n",
    "    df = pd.read_csv(\"boston_data.csv\")\n",
    "    df_train = df.sample(frac=2.0/3)\n",
    "    df_test = df.drop(df_train.index)\n",
    "\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "    X_train = df_train.drop(\"MEDV\", axis=1).to_numpy()\n",
    "    y_train = df_train[\"MEDV\"].to_numpy()\n",
    "\n",
    "    X_test = df_test.drop(\"MEDV\", axis=1).to_numpy()\n",
    "    y_test = df_test[\"MEDV\"].to_numpy()\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8fcad3",
   "metadata": {},
   "source": [
    "### Part (a) - Linear regression with constant function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6ffb0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train: 85.57766007449216\n",
      "STDEV train: 4.025731642599331\n",
      "MSE test:  82.28102496404838\n",
      "STDEV test: 8.102826162234736\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def constant_regression():\n",
    "    \"\"\"Fits a constant to the data set using linear regression\"\"\"\n",
    "\n",
    "    mse_train_values = []\n",
    "    mse_test_values = []\n",
    "\n",
    "    for _ in range(20):\n",
    "\n",
    "        X_train, y_train, X_test, y_test = get_train_test_data()\n",
    "\n",
    "        m_train, m_test = len(X_train), len(X_test)\n",
    "\n",
    "        phi_train = np.ones(m_train).reshape(-1, 1)\n",
    "\n",
    "        a = np.linalg.lstsq(phi_train, y_train)[0] # best fit constant\n",
    "        mse_train = (1.0/m_train) * np.linalg.norm(np.dot(phi_train, a) - y_train)**2\n",
    "        mse_train_values.append(mse_train)\n",
    "\n",
    "        phi_test = np.ones(m_test).reshape(-1, 1)\n",
    "\n",
    "        mse_test = (1.0/m_test) * np.linalg.norm(np.dot(phi_test, a) -  y_test)**2\n",
    "        mse_test_values.append(mse_test)\n",
    "\n",
    "    return np.mean(mse_train_values), np.std(mse_train_values), np.mean(mse_test_values), np.std(mse_test_values)\n",
    "\n",
    "\n",
    "mse_train, std_train, mse_test, std_test = constant_regression()\n",
    "print(f\"MSE train: {mse_train}\")\n",
    "print(f\"STDEV train: {std_train}\")\n",
    "print(f\"MSE test:  {mse_test}\")\n",
    "print(f\"STDEV test: {std_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c64008",
   "metadata": {},
   "source": [
    "### Part (c) - Linear regression with a single attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "074eba55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressing on variable 0\n",
      "MSE train: 69.14633677238865\n",
      "STDEV train: 5.0490214472888235\n",
      "MSE test:  77.58740472403565\n",
      "STDEV test: 10.384364939208272\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 1\n",
      "MSE train: 74.42287658330942\n",
      "STDEV train: 5.496585792499465\n",
      "MSE test:  72.10619290812521\n",
      "STDEV test: 10.97048801118607\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 2\n",
      "MSE train: 66.52577545053178\n",
      "STDEV train: 5.162550358617958\n",
      "MSE test:  61.361102747395115\n",
      "STDEV test: 10.221261869664172\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 3\n",
      "MSE train: 82.01799758797901\n",
      "STDEV train: 4.046246873520158\n",
      "MSE test:  82.37342617811875\n",
      "STDEV test: 8.276743345766329\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 4\n",
      "MSE train: 70.73711010790538\n",
      "STDEV train: 4.841096064947621\n",
      "MSE test:  66.06869331542647\n",
      "STDEV test: 9.572182121086621\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 5\n",
      "MSE train: 43.17798706936062\n",
      "STDEV train: 3.267120731188424\n",
      "MSE test:  44.95319112236179\n",
      "STDEV test: 6.56157723240285\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 6\n",
      "MSE train: 70.4561615645768\n",
      "STDEV train: 5.027091744472598\n",
      "MSE test:  76.75007561999229\n",
      "STDEV test: 10.20124082762442\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 7\n",
      "MSE train: 79.9038169774837\n",
      "STDEV train: 3.655221144225045\n",
      "MSE test:  78.02118234751521\n",
      "STDEV test: 7.269387456819465\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 8\n",
      "MSE train: 72.37377466684487\n",
      "STDEV train: 6.18813413962661\n",
      "MSE test:  71.98925850022377\n",
      "STDEV test: 12.330107050255824\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 9\n",
      "MSE train: 66.59881805368\n",
      "STDEV train: 4.346150541290759\n",
      "MSE test:  64.8912179583758\n",
      "STDEV test: 8.799160451814629\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 10\n",
      "MSE train: 63.38656177870506\n",
      "STDEV train: 3.4114947170019416\n",
      "MSE test:  61.618236592918265\n",
      "STDEV test: 6.919655845781998\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 11\n",
      "MSE train: 38.8723383598836\n",
      "STDEV train: 2.665064294977555\n",
      "MSE test:  37.9835610806286\n",
      "STDEV test: 5.385937618225127\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def single_attribute_regression(index):\n",
    "    \"\"\"Does linear regression with a bias term with a single attribute given by the index. \"\"\"\n",
    "    \n",
    "    mse_train_values = []\n",
    "    mse_test_values = []\n",
    "\n",
    "    for _ in range(20):\n",
    "\n",
    "        X_train, y_train, X_test, y_test = get_train_test_data()\n",
    "        m_train, m_test = len(X_train), len(X_test)\n",
    "\n",
    "        X_train = X_train[:, index]\n",
    "        phi_train = np.column_stack((X_train, np.ones_like(X_train)))\n",
    "        \n",
    "\n",
    "        X_test = X_test[:, index]\n",
    "        phi_test = np.column_stack((X_test, np.ones_like(X_test)))\n",
    "\n",
    "        w = np.linalg.lstsq(phi_train, y_train)[0] # best fit weight vector\n",
    "        mse_train = (1.0/m_train) * np.linalg.norm(np.dot(phi_train, w) - y_train)**2\n",
    "        mse_train_values.append(mse_train)\n",
    "\n",
    "        mse_test = (1.0/m_test) * np.linalg.norm(np.dot(phi_test, w) -  y_test)**2\n",
    "        mse_test_values.append(mse_test)\n",
    "\n",
    "    return np.mean(mse_train_values), np.std(mse_train_values), np.mean(mse_test_values), np.std(mse_test_values)\n",
    "\n",
    "\n",
    "for i in range(12):\n",
    "    print(f\"Regressing on variable {i}\")\n",
    "    mse_train, std_train, mse_test, std_test = single_attribute_regression(i)\n",
    "    print(f\"MSE train: {mse_train}\")\n",
    "    print(f\"STDEV train: {std_train}\")\n",
    "    print(f\"MSE test:  {mse_test}\")\n",
    "    print(f\"STDEV test: {std_test}\")\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b5504f",
   "metadata": {},
   "source": [
    "### Part (d) - Linear regression with all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b01f0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train: 21.59648382198481\n",
      "STDEV train: 2.521958816821923\n",
      "MSE test:  25.596786143015855\n",
      "STDEV test: 5.364899178873035\n"
     ]
    }
   ],
   "source": [
    "def all_attributes_regression():\n",
    "    \"\"\"Does linear regression with a bias term with a single attribute given by the index. \"\"\"\n",
    "    \n",
    "    mse_train_values = []\n",
    "    mse_test_values = []\n",
    "\n",
    "    for _ in range(20):\n",
    "\n",
    "        X_train, y_train, X_test, y_test = get_train_test_data()\n",
    "        m_train, m_test = len(X_train), len(X_test)\n",
    "        phi_train = np.column_stack((X_train, np.ones(m_train)))\n",
    "\n",
    "        w = np.linalg.lstsq(phi_train, y_train)[0] \n",
    "        mse_train = (1.0/m_train) * np.linalg.norm(np.dot(phi_train, w) - y_train)**2\n",
    "        mse_train_values.append(mse_train)\n",
    "\n",
    "        phi_test = np.column_stack((X_test, np.ones(m_test)))\n",
    "        mse_test = (1.0/m_test) * np.linalg.norm(np.dot(phi_test, w) -  y_test)**2\n",
    "        mse_test_values.append(mse_test)\n",
    "    \n",
    "    return np.mean(mse_train_values), np.std(mse_train_values), np.mean(mse_test_values), np.std(mse_test_values)\n",
    "\n",
    "mse_train, std_train, mse_test, std_test = all_attributes_regression()\n",
    "\n",
    "print(f\"MSE train: {mse_train}\")\n",
    "print(f\"STDEV train: {std_train}\")\n",
    "print(f\"MSE test:  {mse_test}\")\n",
    "print(f\"STDEV test: {std_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9432e11",
   "metadata": {},
   "source": [
    "# 1.3.5 Filtered Boston housing and kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a681e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KRR:\n",
    "\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.pairwise_norm = self._get_pairwise_norm(X_train)\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def _get_pairwise_norm(self, X_train):\n",
    "        m = len(X_train)\n",
    "        M = np.zeros((m, m))\n",
    "        for i in range(m):\n",
    "            for j in range(m):\n",
    "                M[i, j] = np.linalg.norm(X_train[i] - X_train[j])\n",
    "        return M\n",
    "\n",
    "    def get_alpha(self, gamma, sigma):\n",
    "        m = len(self.y_train)\n",
    "        K = np.exp(-((self.pairwise_norm/sigma)**2)/2.0)\n",
    "        M = K + gamma * m * np.identity(m)\n",
    "        alpha = np.linalg.solve(M, self.y_train)\n",
    "        return alpha\n",
    "        \n",
    "    def predict(self, X_test, gamma, sigma):\n",
    "        alpha = self.get_alpha(gamma, sigma)\n",
    "        diff = self.X_train[:, None, :] - X_test[None, :, :] # diff[i][j] = X_train[i] - X_test[j]\n",
    "        norms = np.linalg.norm(diff, axis=2) # norms[i][j] = ||X_train[i] - X_test[j]||\n",
    "\n",
    "        k = np.exp(-((norms/sigma)**2)/2)\n",
    "\n",
    "        y_preds = np.dot(alpha, k) # dots alpha with each column of norms\n",
    "\n",
    "        return y_preds\n",
    "\n",
    "    def get_mse(self, X_test, y_test, gamma, sigma):\n",
    "        y_preds = self.predict(X_test, gamma, sigma)\n",
    "    \n",
    "        return (np.linalg.norm(y_preds - y_test)**2)/len(X_test)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d3b17a",
   "metadata": {},
   "source": [
    "### Part (a) - Hyperparameter optimisation of sigma and gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43152bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def get_cross_validation_error(folds_X, folds_y, gamma, sigma):\n",
    "\n",
    "    num_folds = len(folds_X)\n",
    "\n",
    "    def get_fold_error(i):\n",
    "        fold_X_test = folds_X[i]\n",
    "        fold_y_test = folds_y[i]\n",
    "        fold_X_train = np.concatenate([folds_X[j] for j in range(num_folds) if j != i])\n",
    "        fold_y_train = np.concatenate([folds_y[j] for j in range(num_folds) if j != i])\n",
    "        krr = KRR(fold_X_train, fold_y_train)\n",
    "        return krr.get_mse(fold_X_test, fold_y_test, gamma, sigma)\n",
    "    \n",
    "    # parallelism across folds for speedup\n",
    "    errors = Parallel(n_jobs=-1)(delayed(get_fold_error)(i) for i in range(num_folds))\n",
    "\n",
    "    return np.mean(errors)\n",
    "\n",
    "\n",
    "def get_best_params(X_train, y_train):\n",
    "    \"\"\"Gets the best pair of values (gamma, sigma) to use for ridge regression.\n",
    "    by doing five-fold validation on the given training data.\"\"\"\n",
    "\n",
    "    num_folds = 5\n",
    "    gammas = 2.0 ** np.arange(-40, -25)\n",
    "    sigmas = 2.0 ** np.arange(7.0, 13.1, 0.5)\n",
    "\n",
    "    folds_X = np.array_split(X_train, num_folds)\n",
    "    folds_y = np.array_split(y_train, num_folds)\n",
    "\n",
    "    min_cross_error = np.inf\n",
    "\n",
    "    best_gamma, best_sigma = 0, 0\n",
    "\n",
    "    errors = np.zeros(shape=(len(gammas), len(sigmas))) # errors[i][j] = cross validation error using gammas[i] and sigmas[j]\n",
    "\n",
    "    for i, gamma in enumerate(gammas):\n",
    "        for j, sigma in enumerate(sigmas):\n",
    "            cross_error = get_cross_validation_error(folds_X, folds_y, gamma, sigma)\n",
    "            if cross_error < min_cross_error:\n",
    "                min_cross_error = cross_error\n",
    "                best_gamma, best_sigma = gamma, sigma\n",
    "            \n",
    "            errors[i][j] = cross_error\n",
    "\n",
    "    return best_gamma, best_sigma, errors\n",
    "\n",
    "def kernelised_ridge_regression():\n",
    "    \"\"\"Does kernelised ridge regression using best gamma and sigma values found from cross-fold validation.\"\"\"\n",
    "    \n",
    "    mse_train_values = []\n",
    "    mse_test_values = []\n",
    "\n",
    "    for _ in range(20):\n",
    "\n",
    "        X_train, y_train, X_test, y_test = get_train_test_data()\n",
    "\n",
    "        gamma, sigma, _ = get_best_params(X_train, y_train)\n",
    "\n",
    "        krr = KRR(X_train, y_train)\n",
    "\n",
    "        mse_train = krr.get_mse(X_train, y_train, gamma, sigma)\n",
    "        mse_train_values.append(mse_train)\n",
    "\n",
    "        mse_test = krr.get_mse(X_test, y_test, gamma, sigma)\n",
    "        mse_test_values.append(mse_test)\n",
    "    \n",
    "    return np.mean(mse_train_values), np.std(mse_train_values), np.mean(mse_test_values), np.std(mse_test_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bbb83e",
   "metadata": {},
   "source": [
    "### Part (b) - Plot of cross-validation error for different values of sigma and gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71c1120",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# get best here and plot in this cell then without calling again use best values to fgind test and train mse values \u001b[39;00m\n\u001b[32m      3\u001b[39m X_train, y_train, X_test, y_test = get_train_test_data()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m gamma, sigma, errors = \u001b[43mget_best_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest gamma: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgamma\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest sigma: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msigma\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mget_best_params\u001b[39m\u001b[34m(X_train, y_train)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, gamma \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(gammas):\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m j, sigma \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sigmas):\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m         cross_error = \u001b[43mget_cross_validation_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolds_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolds_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m cross_error < min_cross_error:\n\u001b[32m     42\u001b[39m             min_cross_error = cross_error\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mget_cross_validation_error\u001b[39m\u001b[34m(folds_X, folds_y, gamma, sigma)\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m krr.get_mse(fold_X_test, fold_y_test, gamma, sigma)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# parallelism across folds for speedup\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m errors = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_fold_error\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_folds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m np.mean(errors)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/supervised_cw1/venv/lib/python3.14/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/supervised_cw1/venv/lib/python3.14/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/supervised_cw1/venv/lib/python3.14/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# get best here and plot in this cell then without calling again use best values to fgind test and train mse values \n",
    "\n",
    "X_train, y_train, X_test, y_test = get_train_test_data()\n",
    "gamma, sigma, errors = get_best_params(X_train, y_train)\n",
    "\n",
    "print(f\"Best gamma: {gamma}\")\n",
    "print(f\"Best sigma: {sigma}\")\n",
    "\n",
    "#TODO: 3D plot of MSE here !\n",
    "\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65403581",
   "metadata": {},
   "source": [
    "### Part (c) - Test/train MSE for best sigma and gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d2b2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train: 5.60937539629866\n",
      "MSE test: 14.151779629854182\n"
     ]
    }
   ],
   "source": [
    "krr = KRR(X_train, y_train)\n",
    "\n",
    "mse_train = krr.get_mse(X_train, y_train, gamma, sigma)\n",
    "mse_test = krr.get_mse(X_test, y_test, gamma, sigma)\n",
    "\n",
    "print(f\"MSE train: {mse_train}\")\n",
    "print(f\"MSE test: {mse_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8949962e",
   "metadata": {},
   "source": [
    "### Part (d) - Test/train MSE for all the above methods averaged for 20 runs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836aa5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive regression\n",
      "MSE train: 82.37 ± 4.71\n",
      "MSE test:  88.69 ± 9.52\n",
      "\n",
      "\n",
      "Linear Regression (attribute 1)\n",
      "MSE train: 70.9 ± 3.79\n",
      "MSE test:  73.77 ± 7.66\n",
      "\n",
      "\n",
      "Linear Regression (attribute 2)\n",
      "MSE train: 73.14 ± 4.54\n",
      "MSE test:  74.47 ± 9.08\n",
      "\n",
      "\n",
      "Linear Regression (attribute 3)\n",
      "MSE train: 63.11 ± 5.42\n",
      "MSE test:  68.15 ± 10.92\n",
      "\n",
      "\n",
      "Linear Regression (attribute 4)\n",
      "MSE train: 82.13 ± 4.74\n",
      "MSE test:  82.16 ± 9.6\n",
      "\n",
      "\n",
      "Linear Regression (attribute 5)\n",
      "MSE train: 69.01 ± 5.3\n",
      "MSE test:  69.35 ± 10.66\n",
      "\n",
      "\n",
      "Linear Regression (attribute 6)\n",
      "MSE train: 44.43 ± 3.96\n",
      "MSE test:  42.38 ± 7.98\n",
      "\n",
      "\n",
      "Linear Regression (attribute 7)\n",
      "MSE train: 70.24 ± 5.06\n",
      "MSE test:  77.22 ± 10.34\n",
      "\n",
      "\n",
      "Linear Regression (attribute 8)\n",
      "MSE train: 78.76 ± 3.8\n",
      "MSE test:  80.36 ± 7.61\n",
      "\n",
      "\n",
      "Linear Regression (attribute 9)\n",
      "MSE train: 71.59 ± 4.55\n",
      "MSE test:  73.65 ± 9.15\n",
      "\n",
      "\n",
      "Linear Regression (attribute 10)\n",
      "MSE train: 65.02 ± 5.33\n",
      "MSE test:  68.16 ± 10.64\n",
      "\n",
      "\n",
      "Linear Regression (attribute 11)\n",
      "MSE train: 61.74 ± 3.74\n",
      "MSE test:  64.94 ± 7.69\n",
      "\n",
      "\n",
      "Linear Regression (attribute 12)\n",
      "MSE train: 37.96 ± 2.47\n",
      "MSE test:  39.88 ± 5.1\n",
      "\n",
      "\n",
      "Linear Regression (all attributes)\n",
      "MSE train: 22.28 ± 1.66\n",
      "MSE test:  24.06 ± 4.12\n",
      "\n",
      "\n",
      "Kernel Ridge Regression\n"
     ]
    }
   ],
   "source": [
    "mse_train, std_train, mse_test, std_test = constant_regression()\n",
    "print(\"Naive regression\")\n",
    "print(f\"MSE train: {mse_train.round(2)} ± {std_train.round(2)}\")\n",
    "print(f\"MSE test:  {mse_test.round(2)} ± {std_test.round(2)}\")\n",
    "\n",
    "for i in range(12):\n",
    "    print(\"\\n\")\n",
    "    print(f\"Linear Regression (attribute {i+1})\")\n",
    "    mse_train, std_train, mse_test, std_test = single_attribute_regression(i)\n",
    "    print(f\"MSE train: {mse_train.round(2)} ± {std_train.round(2)}\")\n",
    "    print(f\"MSE test:  {mse_test.round(2)} ± {std_test.round(2)}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Linear Regression (all attributes)\")\n",
    "mse_train, std_train, mse_test, std_test = all_attributes_regression()\n",
    "print(f\"MSE train: {mse_train.round(2)} ± {std_train.round(2)}\")\n",
    "print(f\"MSE test:  {mse_test.round(2)} ± {std_test.round(2)}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Kernel Ridge Regression\")\n",
    "mse_train, std_train, mse_test, std_test = kernelised_ridge_regression()\n",
    "print(f\"MSE train: {mse_train.round(2)} ± {std_train.round(2)}\")\n",
    "print(f\"MSE test:  {mse_test.round(2)} ± {std_test.round(2)}\")\n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
