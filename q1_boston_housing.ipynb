{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a66dfa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c7f189",
   "metadata": {},
   "source": [
    "# 1.2 Filtered Boston housing and kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74a8919",
   "metadata": {},
   "source": [
    "## 1.2.4: Baseline vs full linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32015d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data():\n",
    "    df = pd.read_csv(\"boston_data.csv\")\n",
    "    df_train = df.sample(frac=2.0/3)\n",
    "    df_test = df.drop(df_train.index)\n",
    "\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "    X_train = df_train.drop(\"MEDV\", axis=1).to_numpy()\n",
    "    y_train = df_train[\"MEDV\"].to_numpy()\n",
    "\n",
    "    X_test = df_test.drop(\"MEDV\", axis=1).to_numpy()\n",
    "    y_test = df_test[\"MEDV\"].to_numpy()\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8fcad3",
   "metadata": {},
   "source": [
    "### Part (a) - Linear regression with constant function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6ffb0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train: 81.76217595470595\n",
      "STDEV train: 4.994606544286939\n",
      "MSE test:  89.92771137344184\n",
      "STDEV test: 9.98019379935081\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def constant_regression():\n",
    "    \"\"\"Fits a constant to the data set using linear regression\"\"\"\n",
    "\n",
    "    mse_train_values = []\n",
    "    mse_test_values = []\n",
    "\n",
    "    for _ in range(20):\n",
    "\n",
    "        X_train, y_train, X_test, y_test = get_train_test_data()\n",
    "\n",
    "        m_train, m_test = len(X_train), len(X_test)\n",
    "\n",
    "        phi_train = np.ones(m_train).reshape(-1, 1)\n",
    "\n",
    "        a = np.linalg.lstsq(phi_train, y_train)[0] # best fit constant\n",
    "        mse_train = (1.0/m_train) * np.linalg.norm(np.dot(phi_train, a) - y_train)**2\n",
    "        mse_train_values.append(mse_train)\n",
    "\n",
    "        phi_test = np.ones(m_test).reshape(-1, 1)\n",
    "\n",
    "        mse_test = (1.0/m_test) * np.linalg.norm(np.dot(phi_test, a) -  y_test)**2\n",
    "        mse_test_values.append(mse_test)\n",
    "\n",
    "    return np.mean(mse_train_values), np.std(mse_train_values), np.mean(mse_test_values), np.std(mse_test_values)\n",
    "\n",
    "\n",
    "mse_train, std_train, mse_test, std_test = constant_regression()\n",
    "print(f\"MSE train: {mse_train}\")\n",
    "print(f\"STDEV train: {std_train}\")\n",
    "print(f\"MSE test:  {mse_test}\")\n",
    "print(f\"STDEV test: {std_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c64008",
   "metadata": {},
   "source": [
    "### Part (c) - Linear regression with a single attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "074eba55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressing on variable 0\n",
      "MSE train: 70.16958853648867\n",
      "STDEV train: 3.8804582086632413\n",
      "MSE test:  76.09580813052492\n",
      "STDEV test: 8.300932155555811\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 1\n",
      "MSE train: 74.71191750968053\n",
      "STDEV train: 5.0432032900833486\n",
      "MSE test:  71.47342561942729\n",
      "STDEV test: 9.900873702841436\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 2\n",
      "MSE train: 64.31011914302483\n",
      "STDEV train: 4.290270541823158\n",
      "MSE test:  65.89358426659177\n",
      "STDEV test: 8.598513983717593\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 3\n",
      "MSE train: 82.51321853875527\n",
      "STDEV train: 4.788182862377677\n",
      "MSE test:  80.80106295274359\n",
      "STDEV test: 9.671204369554383\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 4\n",
      "MSE train: 67.64838072001758\n",
      "STDEV train: 6.069222019562323\n",
      "MSE test:  72.24252814424088\n",
      "STDEV test: 12.05331194556931\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 5\n",
      "MSE train: 42.71144872500424\n",
      "STDEV train: 4.092043027499033\n",
      "MSE test:  45.82626806049116\n",
      "STDEV test: 8.115517852520506\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 6\n",
      "MSE train: 72.65770425992363\n",
      "STDEV train: 5.467864849622816\n",
      "MSE test:  72.4667215438165\n",
      "STDEV test: 10.901524550764105\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 7\n",
      "MSE train: 78.91196541814129\n",
      "STDEV train: 5.361604660294188\n",
      "MSE test:  80.1497169344952\n",
      "STDEV test: 10.72030870852404\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 8\n",
      "MSE train: 70.42634032942762\n",
      "STDEV train: 4.2411620429598775\n",
      "MSE test:  75.84300259129134\n",
      "STDEV test: 8.703899457189642\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 9\n",
      "MSE train: 63.67877344860291\n",
      "STDEV train: 4.979050333927602\n",
      "MSE test:  70.69645055946191\n",
      "STDEV test: 9.949231565325494\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 10\n",
      "MSE train: 62.68023527726187\n",
      "STDEV train: 3.9051866381478577\n",
      "MSE test:  62.944203449129574\n",
      "STDEV test: 7.904423692226097\n",
      "\n",
      "\n",
      "\n",
      "Regressing on variable 11\n",
      "MSE train: 38.26282373788515\n",
      "STDEV train: 2.1488061004656314\n",
      "MSE test:  39.22998650329471\n",
      "STDEV test: 4.192446575347241\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def single_attribute_regression(index):\n",
    "    \"\"\"Does linear regression with a bias term with a single attribute given by the index. \"\"\"\n",
    "    \n",
    "    mse_train_values = []\n",
    "    mse_test_values = []\n",
    "\n",
    "    for _ in range(20):\n",
    "\n",
    "        X_train, y_train, X_test, y_test = get_train_test_data()\n",
    "        m_train, m_test = len(X_train), len(X_test)\n",
    "\n",
    "        X_train = X_train[:, index]\n",
    "        phi_train = np.column_stack((X_train, np.ones_like(X_train)))\n",
    "        \n",
    "\n",
    "        X_test = X_test[:, index]\n",
    "        phi_test = np.column_stack((X_test, np.ones_like(X_test)))\n",
    "\n",
    "        w = np.linalg.lstsq(phi_train, y_train)[0] # best fit weight vector\n",
    "        mse_train = (1.0/m_train) * np.linalg.norm(np.dot(phi_train, w) - y_train)**2\n",
    "        mse_train_values.append(mse_train)\n",
    "\n",
    "        mse_test = (1.0/m_test) * np.linalg.norm(np.dot(phi_test, w) -  y_test)**2\n",
    "        mse_test_values.append(mse_test)\n",
    "\n",
    "    return np.mean(mse_train_values), np.std(mse_train_values), np.mean(mse_test_values), np.std(mse_test_values)\n",
    "\n",
    "\n",
    "for i in range(12):\n",
    "    print(f\"Regressing on variable {i}\")\n",
    "    mse_train, std_train, mse_test, std_test = single_attribute_regression(i)\n",
    "    print(f\"MSE train: {mse_train}\")\n",
    "    print(f\"STDEV train: {std_train}\")\n",
    "    print(f\"MSE test:  {mse_test}\")\n",
    "    print(f\"STDEV test: {std_test}\")\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b5504f",
   "metadata": {},
   "source": [
    "### Part (d) - Linear regression with all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8b01f0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train: 23.044043073978294\n",
      "STDEV train: 2.181288693491689\n",
      "MSE test:  22.565300261884058\n",
      "STDEV test: 4.6115414249210005\n"
     ]
    }
   ],
   "source": [
    "def all_attributes_regression():\n",
    "    \"\"\"Does linear regression with a bias term with a single attribute given by the index. \"\"\"\n",
    "    \n",
    "    mse_train_values = []\n",
    "    mse_test_values = []\n",
    "\n",
    "    for _ in range(20):\n",
    "\n",
    "        X_train, y_train, X_test, y_test = get_train_test_data()\n",
    "        m_train, m_test = len(X_train), len(X_test)\n",
    "        phi_train = np.column_stack((X_train, np.ones(m_train)))\n",
    "\n",
    "        w = np.linalg.lstsq(phi_train, y_train)[0] \n",
    "        mse_train = (1.0/m_train) * np.linalg.norm(np.dot(phi_train, w) - y_train)**2\n",
    "        mse_train_values.append(mse_train)\n",
    "\n",
    "        phi_test = np.column_stack((X_test, np.ones(m_test)))\n",
    "        mse_test = (1.0/m_test) * np.linalg.norm(np.dot(phi_test, w) -  y_test)**2\n",
    "        mse_test_values.append(mse_test)\n",
    "    \n",
    "    return np.mean(mse_train_values), np.std(mse_train_values), np.mean(mse_test_values), np.std(mse_test_values)\n",
    "\n",
    "mse_train, std_train, mse_test, std_test = all_attributes_regression()\n",
    "\n",
    "print(f\"MSE train: {mse_train}\")\n",
    "print(f\"STDEV train: {std_train}\")\n",
    "print(f\"MSE test:  {mse_test}\")\n",
    "print(f\"STDEV test: {std_test}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9432e11",
   "metadata": {},
   "source": [
    "# 1.3.5 Filtered Boston housing and kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a681e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KRR:\n",
    "\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.pairwise_norm = self._get_pairwise_norm(X_train)\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def _get_pairwise_norm(self, X_train):\n",
    "        m = len(X_train)\n",
    "        M = np.zeros((m, m))\n",
    "        for i in range(m):\n",
    "            for j in range(m):\n",
    "                M[i, j] = np.linalg.norm(X_train[i] - X_train[j])\n",
    "        return M\n",
    "\n",
    "    def get_alpha(self, gamma, sigma):\n",
    "        m = len(self.y_train)\n",
    "        K = np.exp(-((self.pairwise_norm/sigma)**2)/2.0)\n",
    "        M = K + gamma * m * np.identity(m)\n",
    "        alpha = np.linalg.solve(M, self.y_train)\n",
    "        return alpha\n",
    "        \n",
    "    def predict(self, X_test, gamma, sigma):\n",
    "        alpha = self.get_alpha(gamma, sigma)\n",
    "        diff = self.X_train[:, None, :] - X_test[None, :, :] # diff[i][j] = X_train[i] - X_test[j]\n",
    "        norms = np.linalg.norm(diff, axis=2) # norms[i][j] = ||X_train[i] - X_test[j]||\n",
    "\n",
    "        k = np.exp(-((norms/sigma)**2)/2)\n",
    "\n",
    "        y_preds = np.dot(alpha, k) # dots alpha with each column of norms\n",
    "\n",
    "        return y_preds\n",
    "\n",
    "    def get_mse(self, X_test, y_test, gamma, sigma):\n",
    "        y_preds = self.predict(X_test, gamma, sigma)\n",
    "    \n",
    "        return (np.linalg.norm(y_preds - y_test)**2)/len(X_test)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d3b17a",
   "metadata": {},
   "source": [
    "### Part (a) - Hyperparameter optimisation of sigma and gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43152bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.450580596923828e-09 362.03867196751236\n",
      "3.725290298461914e-09 256.0\n",
      "4.656612873077393e-10 1024.0\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def get_cross_validation_error(folds_X, folds_y, gamma, sigma):\n",
    "\n",
    "    num_folds = len(folds_X)\n",
    "\n",
    "    def get_fold_error(i):\n",
    "        fold_X_test = folds_X[i]\n",
    "        fold_y_test = folds_y[i]\n",
    "        fold_X_train = np.concatenate([folds_X[j] for j in range(num_folds) if j != i])\n",
    "        fold_y_train = np.concatenate([folds_y[j] for j in range(num_folds) if j != i])\n",
    "        krr = KRR(fold_X_train, fold_y_train)\n",
    "        return krr.get_mse(fold_X_test, fold_y_test, gamma, sigma)\n",
    "    \n",
    "    # parallelism across folds for speedup\n",
    "    errors = Parallel(n_jobs=-1)(delayed(get_fold_error)(i) for i in range(num_folds))\n",
    "\n",
    "    return np.mean(errors)\n",
    "\n",
    "\n",
    "def get_best_params(X_train, y_train):\n",
    "    \"\"\"Gets the best pair of values (gamma, sigma) to use for ridge regression.\n",
    "    by doing five-fold validation on the given training data.\"\"\"\n",
    "\n",
    "    num_folds = 5\n",
    "    gammas = 2.0 ** np.arange(-40, -25)\n",
    "    sigmas = 2.0 ** np.arange(7.0, 13.1, 0.5)\n",
    "\n",
    "    folds_X = np.array_split(X_train, num_folds)\n",
    "    folds_y = np.array_split(y_train, num_folds)\n",
    "\n",
    "    min_cross_error = np.inf\n",
    "\n",
    "    best_gamma, best_sigma = 0, 0\n",
    "\n",
    "    errors = np.zeros(shape=(len(gammas), len(sigmas))) # errors[i][j] = cross validation error using gammas[i] and sigmas[j]\n",
    "\n",
    "    for i, gamma in enumerate(gammas):\n",
    "        for j, sigma in enumerate(sigmas):\n",
    "            cross_error = get_cross_validation_error(folds_X, folds_y, gamma, sigma)\n",
    "            if cross_error < min_cross_error:\n",
    "                min_cross_error = cross_error\n",
    "                best_gamma, best_sigma = gamma, sigma\n",
    "            \n",
    "            errors[i][j] = cross_error\n",
    "\n",
    "    return best_gamma, best_sigma, errors\n",
    "\n",
    "def kernelised_ridge_regression():\n",
    "    \"\"\"Does kernelised ridge regression using best gamma and sigma values found from cross-fold validation. \"\"\"\n",
    "    \n",
    "    mse_train_values = []\n",
    "    mse_test_values = []\n",
    "\n",
    "    for _ in range(20):\n",
    "\n",
    "        X_train, y_train, X_test, y_test = get_train_test_data()\n",
    "\n",
    "        gamma, sigma, _ = get_best_params(X_train, y_train)\n",
    "\n",
    "        krr = KRR(X_train, y_train)\n",
    "\n",
    "        mse_train = krr.get_mse(X_train, y_train, gamma, sigma)\n",
    "        mse_train_values.append(mse_train)\n",
    "\n",
    "        mse_test = krr.get_mse(X_test, y_test, gamma, sigma)\n",
    "        mse_test_values.append(mse_test)\n",
    "    \n",
    "    return np.mean(mse_train_values), np.std(mse_train_values), np.mean(mse_test_values), np.std(mse_test_values)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bbb83e",
   "metadata": {},
   "source": [
    "### Part (b) - Plot of cross-validation error for different values of sigma and gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71c1120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best gamma: 1.8189894035458565e-12\n",
      "Best sigma: 1024.0\n",
      "[[ 573.4037687  2929.61507567 3411.2474111   479.44861909   34.25364645\n",
      "    16.96078408   13.02313226   13.35990231   15.21947747   16.0904\n",
      "    14.36134125   13.14385719   14.50240617]\n",
      " [ 793.81474037 3503.75692617 2188.39675413  159.00795306   25.97578095\n",
      "    15.2449257    12.95751673   13.83722121   15.75566624   15.36193469\n",
      "    13.51498102   13.4351248    16.25255086]\n",
      " [1256.68179707 3500.90811678 1090.17121072   58.59882173   21.79487693\n",
      "    14.01061372   13.1262667    14.44715761   15.81251818   14.3693236\n",
      "    13.149362     14.42767684   18.50445535]\n",
      " [1832.02767945 2815.4951893   424.18597475   32.9852154    18.94468414\n",
      "    13.36212841   13.43959116   15.03927693   15.25519329   13.52742319\n",
      "    13.4240573    16.13454001   20.72520589]\n",
      " [2262.59018935 1776.3181715   142.85166145   25.72655527   16.70190335\n",
      "    13.22637943   13.87940124   15.30202539   14.34041835   13.16166079\n",
      "    14.38933498   18.36860868   22.46089038]\n",
      " [2271.78376606  874.55322124   53.31410453   22.37624288   15.03256086\n",
      "    13.37032901   14.38057818   14.98467266   13.52906158   13.42795189\n",
      "    16.05944917   20.63254652   23.65221008]\n",
      " [1820.17470593  349.71064892   28.41369659   19.81150451   14.0990241\n",
      "    13.63247903   14.71360004   14.22980731   13.17832518   14.38258947\n",
      "    18.27336004   22.4788233    24.4639441 ]\n",
      " [1161.59089516  128.87131286   21.6354837    17.64296044   13.80059435\n",
      "    13.95571191   14.59855257   13.49642424   13.45030657   16.05284643\n",
      "    20.58846616   23.80146397   25.01685662]\n",
      " [ 600.77621502   53.59260302   19.45690663   16.06034094   13.82688151\n",
      "    14.22669906   14.03543605   13.19185911   14.41961105   18.289859\n",
      "    22.55547724   24.67973069   25.35038341]\n",
      " [ 266.61829948   29.48203319   18.15222039   15.15420841   13.93926334\n",
      "    14.23457079   13.41158469   13.5053099    16.13694372   20.65287708\n",
      "    23.9676071    25.2007365    25.51944962]\n",
      " [ 114.97113879   21.26568486   17.11365409   14.76381692   14.02650018\n",
      "    13.86728621   13.18553383   14.52917031   18.43469304   22.65963205\n",
      "    24.83667985   25.46750761   25.63392384]\n",
      " [  56.35933159   17.8803929    16.39929504   14.59137399   13.99027963\n",
      "    13.35682334   13.59355611   16.31467476   20.80513345   24.06153849\n",
      "    25.3023876    25.62596689   25.83624108]\n",
      " [  33.81577942   16.27639857   16.01717313   14.42171006   13.73478718\n",
      "    13.1868893    14.70886476   18.64523338   22.74028108   24.89400985\n",
      "    25.5638572    25.84458374   26.26153823]\n",
      " [  23.97491736   15.75403332   15.78858232   14.15807577   13.3630138\n",
      "    13.6824229    16.54150931   20.96512007   24.06445672   25.37086984\n",
      "    25.83071732   26.2717197    26.98038846]\n",
      " [  18.97745329   15.87856586   15.47331396   13.76375812   13.26654897\n",
      "    14.89231601   18.85338994   22.79625189   24.90407538   25.75292833\n",
      "    26.27733364   26.97530998   28.00924031]]\n"
     ]
    }
   ],
   "source": [
    "# get best here and plot in this cell then without calling again use best values to fgind test and train mse values \n",
    "\n",
    "X_train, y_train, X_test, y_test = get_train_test_data()\n",
    "gamma, sigma, errors = get_best_params(X_train, y_train)\n",
    "\n",
    "print(f\"Best gamma: {gamma}\")\n",
    "print(f\"Best sigma: {sigma}\")\n",
    "\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65403581",
   "metadata": {},
   "source": [
    "### Part (c) - Test/train MSE for best sigma and gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23d2b2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train: 5.60937539629866\n",
      "MSE test: 14.151779629854182\n"
     ]
    }
   ],
   "source": [
    "krr = KRR(X_train, y_train)\n",
    "\n",
    "mse_train = krr.get_mse(X_train, y_train, gamma, sigma)\n",
    "mse_test = krr.get_mse(X_test, y_test, gamma, sigma)\n",
    "\n",
    "print(f\"MSE train: {mse_train}\")\n",
    "print(f\"MSE test: {mse_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8949962e",
   "metadata": {},
   "source": [
    "### Part (d) - Test/train MSE for all the above methods averaged for 20 runs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836aa5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive regression\n",
      "MSE train: 85.52 ± 3.11\n",
      "MSE test:  82.44 ± 6.25\n",
      "\n",
      "\n",
      "Linear Regression (attribute 1)\n",
      "MSE train: 71.05 ± 4.26\n",
      "MSE test:  74.34 ± 10.58\n",
      "\n",
      "\n",
      "Linear Regression (attribute 2)\n",
      "MSE train: 73.56 ± 5.65\n",
      "MSE test:  73.75 ± 11.22\n",
      "\n",
      "\n",
      "Linear Regression (attribute 3)\n",
      "MSE train: 64.49 ± 5.69\n",
      "MSE test:  65.35 ± 11.36\n",
      "\n",
      "\n",
      "Linear Regression (attribute 4)\n",
      "MSE train: 82.08 ± 3.8\n",
      "MSE test:  81.91 ± 7.69\n",
      "\n",
      "\n",
      "Linear Regression (attribute 5)\n",
      "MSE train: 69.86 ± 4.86\n",
      "MSE test:  67.58 ± 9.71\n",
      "\n",
      "\n",
      "Linear Regression (attribute 6)\n",
      "MSE train: 42.87 ± 4.32\n",
      "MSE test:  45.62 ± 8.52\n",
      "\n",
      "\n",
      "Linear Regression (attribute 7)\n",
      "MSE train: 72.5 ± 4.15\n",
      "MSE test:  72.86 ± 8.36\n",
      "\n",
      "\n",
      "Linear Regression (attribute 8)\n",
      "MSE train: 77.86 ± 6.39\n",
      "MSE test:  82.17 ± 12.95\n",
      "\n",
      "\n",
      "Linear Regression (attribute 9)\n",
      "MSE train: 72.36 ± 3.68\n",
      "MSE test:  72.04 ± 7.3\n",
      "\n",
      "\n",
      "Linear Regression (attribute 10)\n",
      "MSE train: 67.14 ± 5.15\n",
      "MSE test:  63.7 ± 10.38\n",
      "\n",
      "\n",
      "Linear Regression (attribute 11)\n",
      "MSE train: 62.14 ± 3.02\n",
      "MSE test:  64.18 ± 6.12\n",
      "\n",
      "\n",
      "Linear Regression (attribute 12)\n",
      "MSE train: 37.84 ± 2.06\n",
      "MSE test:  40.03 ± 4.23\n"
     ]
    }
   ],
   "source": [
    "mse_train, std_train, mse_test, std_test = constant_regression()\n",
    "print(\"Naive regression\")\n",
    "print(f\"MSE train: {mse_train.round(2)} ± {std_train.round(2)}\")\n",
    "print(f\"MSE test:  {mse_test.round(2)} ± {std_test.round(2)}\")\n",
    "\n",
    "for i in range(12):\n",
    "    print(\"\\n\")\n",
    "    print(f\"Linear Regression (attribute {i+1})\")\n",
    "    mse_train, std_train, mse_test, std_test = single_attribute_regression(i)\n",
    "    print(f\"MSE train: {mse_train.round(2)} ± {std_train.round(2)}\")\n",
    "    print(f\"MSE test:  {mse_test.round(2)} ± {std_test.round(2)}\")\n",
    "\n",
    "print(\"Kernel Ridge Regression\")\n",
    "mse_train, std_train, mse_test, std_test = kernelised_ridge_regression()\n",
    "print(f\"MSE train: {mse_train.round(2)} ± {std_train.round(2)}\")\n",
    "print(f\"MSE test:  {mse_test.round(2)} ± {std_test.round(2)}\")\n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
